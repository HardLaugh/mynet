{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "slim =  tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import configuration, inception, crnn\n",
    "from data_utils import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_dir = './data/allSubUni'\n",
    "dataset_dir = './data/output/'\n",
    "file_pattern = 'ocr10_train_*.tfrecord'\n",
    "weights_path='./log/model.ckpt-29001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input = tf.placeholder(tf.uint8, shape=(32, None, 3))\n",
    "image = tf.to_float(img_input)\n",
    "image = tf.expand_dims(image, 0)\n",
    "vocab = vocabulary.Vocabulary()\n",
    "vocab.build()\n",
    "model_config = configuration.ModelConfig()\n",
    "model_config\n",
    "\n",
    "training_config = configuration.TrainingConfig()\n",
    "\n",
    "model = crnn.CRNN(\n",
    "            vocab,\n",
    "            model_config,\n",
    "            mode=\"inference\",\n",
    "        )\n",
    "with tf.variable_scope('CRNN', reuse=False):\n",
    "    image = model.build_image_embeddings(image)\n",
    "    net_out, _ = model.build_model(image)\n",
    "    \n",
    "decodes, _ = tf.nn.ctc_beam_search_decoder(inputs=net_out, sequence_length=25*np.ones(1), merge_repeated=False)\n",
    "pred = tf.sparse_tensor_to_dense(decodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_path = './data/sim_sub_15w/0_0_27HJF30FRY.jpg'\n",
    "#image_path = './data/allSubUni/1612ELL127323C00155.jpg'\n",
    "#image_path = './test_01.jpg'\n",
    "with sess.as_default():\n",
    "        \n",
    "    inputdata = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    #scale = 32.0 / inputdata.shape[0]\n",
    "    #width = max(0 , scale * inputdata.shape[1])\n",
    "    inputdata = cv2.resize(inputdata, (100, 32))\n",
    "    \n",
    "    saver.restore(sess=sess, save_path=weights_path)\n",
    "\n",
    "    out = sess.run(pred, feed_dict={img_input: inputdata})\n",
    "    #preds = decoder.writer.sparse_tensor_to_str(preds[0])\n",
    "    print(vocab._to_string(out[0]))\n",
    "    plt.figure(1)\n",
    "    plt.imshow(cv2.imread(image_path, cv2.IMREAD_COLOR)[:, :, (2, 1, 0)])\n",
    "    plt.figure(2)\n",
    "    plt.imshow(inputdata)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test='jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'jpeg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddir = './data/sim_sub_15w/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = glob.glob(ddir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/sim_sub_15w\\\\0_0_00L61IZ4SA.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './data/sim_sub_15w/'\n",
    "path = './data/allSubUni/'\n",
    "imagefiles = os.listdir(path)\n",
    "for i in range(len(imagefiles)):\n",
    "    imagefiles[i] = os.path.join(path, imagefiles[i])\n",
    "sample_size=2000\n",
    "sample = random.sample([imagefiles[v]\n",
    "                        for v in range(len(imagefiles))], sample_size)\n",
    "shapelist = []\n",
    "for file in sample:\n",
    "    image = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    shapelist.append([*image.shape])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalelist = []\n",
    "\n",
    "for s in shapelist:\n",
    "    scalelist.append(float(s[0]) / s[1])\n",
    "scalelist = np.array(scalelist, np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11868132, 0.15416667, 0.15416667, ..., 0.1       , 0.11868132,\n",
       "       0.1       ], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 40, 1.0)\n",
    "\n",
    "flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "compactness,labels,centers = cv2.kmeans(scalelist, 1, None, criteria, 10, flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13145493]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
