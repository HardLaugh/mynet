{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "slim =  tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import configuration, inception, crnn\n",
    "from data_utils import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_dir = './data/allSubUni'\n",
    "dataset_dir = './data/output/'\n",
    "file_pattern = 'ocr10_train_*.tfrecord'\n",
    "weights_path='./log/model.ckpt-29001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = tf.placeholder(tf.uint8, shape=(32, None, 3))\n",
    "image = tf.to_float(img_input)\n",
    "image = tf.expand_dims(image, 0)\n",
    "vocab = vocabulary.Vocabulary()\n",
    "vocab.build()\n",
    "model_config = configuration.ModelConfig()\n",
    "model_config\n",
    "\n",
    "training_config = configuration.TrainingConfig()\n",
    "\n",
    "model = crnn.CRNN(\n",
    "            vocab,\n",
    "            model_config,\n",
    "            mode=\"inference\",\n",
    "        )\n",
    "with tf.variable_scope('CRNN', reuse=False):\n",
    "    image = model.build_image_embeddings(image)\n",
    "    net_out, _ = model.build_model(image)\n",
    "    \n",
    "decodes, _ = tf.nn.ctc_beam_search_decoder(inputs=net_out, sequence_length=25*np.ones(1), merge_repeated=False)\n",
    "pred = tf.sparse_tensor_to_dense(decodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './data/sim_sub_15w/0_0_27HJF30FRY.jpg'\n",
    "#image_path = './data/allSubUni/1612ELL127323C00155.jpg'\n",
    "#image_path = './test_01.jpg'\n",
    "with sess.as_default():\n",
    "        \n",
    "    inputdata = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    #scale = 32.0 / inputdata.shape[0]\n",
    "    #width = max(0 , scale * inputdata.shape[1])\n",
    "    inputdata = cv2.resize(inputdata, (100, 32))\n",
    "    \n",
    "    saver.restore(sess=sess, save_path=weights_path)\n",
    "\n",
    "    out = sess.run(pred, feed_dict={img_input: inputdata})\n",
    "    #preds = decoder.writer.sparse_tensor_to_str(preds[0])\n",
    "    print(vocab._to_string(out[0]))\n",
    "    plt.figure(1)\n",
    "    plt.imshow(cv2.imread(image_path, cv2.IMREAD_COLOR)[:, :, (2, 1, 0)])\n",
    "    plt.figure(2)\n",
    "    plt.imshow(inputdata)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test='jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'jpeg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = './data/sim_sub_15w/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = glob.glob(ddir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/sim_sub_15w\\\\0_0_00L61IZ4SA.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = vocabulary.Vocabulary()\n",
    "vocab.build()\n",
    "with tf.device('/cpu:0'):\n",
    "    model_config = configuration.ModelConfig()\n",
    "    model_config.batch_size = 1\n",
    "    model_config.dataset_dir = dataset_dir\n",
    "    model_config.input_file_pattern = file_pattern\n",
    "\n",
    "    training_config = configuration.TrainingConfig()\n",
    "\n",
    "    model = crnn.CRNN(\n",
    "        vocab,\n",
    "        model_config,\n",
    "        mode=\"train\",\n",
    "    )\n",
    "    images, input_labels = model.build_inputs()\n",
    "    input_labels = tf.sparse_tensor_to_dense(input_labels)\n",
    "#sess = tf.Session()\n",
    "#sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    with slim.queues.QueueRunners(sess):\n",
    "        for i in range(1):\n",
    "            im, lb = sess.run([images, input_labels])\n",
    "            print(im.shape)\n",
    "            im = np.uint8(im[0,:,:,:])\n",
    "            plt.imshow(im)\n",
    "            plt.show()\n",
    "            print(lb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
